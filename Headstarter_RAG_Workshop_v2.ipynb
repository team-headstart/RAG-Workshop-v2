{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Img](https://app.theheadstarter.com/static/hs-logo-opengraph.png)\n",
        "\n",
        "# Headstarter RAG Workshop\n",
        "\n",
        "**Skills: HuggingFace, LangChain, Pinecone**\n",
        "\n",
        "**Other Resources:**\n",
        "- [Get your Groq API Key](https://console.groq.com/keys)\n",
        "- [Get your Pinecone API Key](https://www.pinecone.io/)"
      ],
      "metadata": {
        "id": "qAAj3apJmnAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### What is RAG anyway?\n",
        "\n",
        "\n",
        "![withoutRAG](https://github.com/user-attachments/assets/649d6101-b63a-4750-997a-b6abc25e5609)\n",
        "\n",
        "![withRAG](https://github.com/user-attachments/assets/e6dd9c46-0bf9-4c31-bd72-a27939ef82b8)\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is a technique primarily used in GenAI applications to improve the quality and accuracy of generated text by LLMs by combining two key processes: retrieval and generation.\n",
        "\n",
        "### Breaking It Down:\n",
        "#### Retrieval:\n",
        "\n",
        "- Before generating a response, the system first looks up relevant information from a large database or knowledge base. This is like searching through a library or the internet to find the most useful facts, articles, or data related to the question or topic.\n",
        "\n",
        "#### Generation:\n",
        "\n",
        "- Once the relevant information is retrieved, the system then uses it to help generate a response. This is where the model, like GPT, creates new text (answers, explanations, etc.) based on the retrieved information."
      ],
      "metadata": {
        "id": "qof4EyLtm4-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install libraries"
      ],
      "metadata": {
        "id": "oKy5DKlZm0a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r5K71LmLS7ze"
      },
      "outputs": [],
      "source": [
        "! pip install langchain langchain-community openai groq tiktoken pinecone-client langchain_pinecone unstructured pdfminer==20191125 pdfminer.six==20221105 pillow_heif unstructured_inference sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, WebBaseLoader, YoutubeLoader, DirectoryLoader, TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from langchain.schema import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = groq_api_key"
      ],
      "metadata": {
        "id": "ay8JWpWbWRQN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the HuggingFace Embeddings client"
      ],
      "metadata": {
        "id": "cgUhMx3EWjdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "Iziy1TmoWRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello my name is Faizan\"\n",
        "\n",
        "query_result = embeddings.embed_query(text)"
      ],
      "metadata": {
        "id": "R3UaJ_7FWn_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_result)"
      ],
      "metadata": {
        "id": "1F88E4puWoCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the Groq client"
      ],
      "metadata": {
        "id": "oVD9c7pdKvHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Free Llama 3.1 API via Groq\n",
        "\n",
        "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))"
      ],
      "metadata": {
        "id": "QwXxemUuWqol"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating sentence similarity with embeddings"
      ],
      "metadata": {
        "id": "aN-sQbs7K3VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)\n",
        "\n",
        "\n",
        "def cosine_similarity_between_sentences(sentence1, sentence2):\n",
        "    # Get embeddings for both sentences\n",
        "    embedding1 = np.array(get_huggingface_embeddings(sentence1))\n",
        "    embedding2 = np.array(get_huggingface_embeddings(sentence2))\n",
        "\n",
        "    # Reshape embeddings for cosine_similarity function\n",
        "    embedding1 = embedding1.reshape(1, -1)\n",
        "    embedding2 = embedding2.reshape(1, -1)\n",
        "\n",
        "    print(\"Embedding for Sentence 1:\", embedding1)\n",
        "    print(\"\\nEmbedding for Sentence 2:\", embedding2)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(embedding1, embedding2)\n",
        "    return similarity[0][0]\n",
        "\n",
        "\n",
        "# Example usage\n",
        "sentence1 = \"I like walking to the park\"\n",
        "sentence2 = \"I like running to the office\"\n",
        "\n",
        "\n",
        "similarity = cosine_similarity_between_sentences(sentence1, sentence2)\n",
        "print(f\"\\n\\nCosine similarity between '{sentence1}' and '{sentence2}': {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "jrSQAyg7WqtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5r9IqANO9GGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLSNcpnO9GI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in the Data\n",
        "\n",
        "Learn more about the dataset [here](https://www.kaggle.com/datasets/ayoubcherguelaine/company-documents-dataset)"
      ],
      "metadata": {
        "id": "7YA0Wj0X-QB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d ayoubcherguelaine/company-documents-dataset\n",
        "! unzip company-documents-dataset.zip"
      ],
      "metadata": {
        "id": "g33q9gobWqrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_directory(directory_path):\n",
        "    data = []\n",
        "    for root, _, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "\n",
        "            file_path = os.path.join(root, file)\n",
        "            print(f\"Processing file: {file_path}\")\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            data.append({\"File\": file_path, \"Data\": loader.load()})\n",
        "\n",
        "    return data\n",
        "\n",
        "directory_path = \"/content/CompanyDocuments\"\n",
        "documents = process_directory(directory_path)\n"
      ],
      "metadata": {
        "id": "2pVe0RMYXvIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2j0tJ_fW9GLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Pinecone"
      ],
      "metadata": {
        "id": "TC2OVunB-_gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to create a Pinecone index with 384 dimensions\n",
        "\n",
        "index_name = \"rag-workshop\"\n",
        "\n",
        "namespace = \"company-documents\"\n",
        "\n",
        "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)"
      ],
      "metadata": {
        "id": "saT1yD_mdHNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6owEozIA--Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insert data into Pinecone"
      ],
      "metadata": {
        "id": "uBwhuuLhAqG-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uT1JvrNF--RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81XIGJn0A2CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hb-KrfY-BdCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LPcxIMBBFqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwIix4L7A2Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PED8FwrW--O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform RAG"
      ],
      "metadata": {
        "id": "5uCoLtHtLwlI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMk_-E0EI0SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQCna1vZI0Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgpTn-j-MLAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WyU4z3JEMLEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cCL3shOvOTZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b613bS_gMLG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_IO4A1bPRri"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5ndG43QPVjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-udZviyaPVlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8C9IRldxPRt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3WdCT44fQAty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kezebsTcPrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "1tTAtCQzUAyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJ2Y6R5DPru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSests6uWRU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzfIFuNCUlvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnHjyXFqVfne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoKC4-DXVfp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}